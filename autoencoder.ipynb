{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tensorflow",
   "display_name": "Python 3.7 (tensorflow)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#Check if GPU is in use.\n",
    "print(f\"tensorflow GPU version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import time\n",
    "import string\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Clear the GPU memory\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Generation resolution - Must be square \n",
    "# Training data is also scaled to this.\n",
    "# Note GENERATE_RES 4 or higher  \n",
    "# will blow Google CoLab's memory and have not\n",
    "# been tested extensivly.\n",
    "\n",
    "GENERATE_RES = 2 # Generation resolution factor \n",
    "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 224 * 2 # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED = 54\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = 'Data/Dataset1000/'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augment_generator(train_image_gen, train_wm_gen, dir_path, shape, seed = 1, batch_size = 5):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "\n",
    "    train_image_generator = train_image_gen.flow_from_directory(f'{dir_path}Original_Ims/', batch_size = batch_size, seed = seed, target_size=(shape, shape), shuffle=False)\n",
    "    train_wm_generator = train_wm_gen.flow_from_directory(f'{dir_path}WM_Images/', batch_size = batch_size, seed = seed, target_size=(shape, shape), shuffle=False)\n",
    "\n",
    "    while True:\n",
    "        X1i = train_image_generator.next()\n",
    "        X2i = train_wm_generator.next()\n",
    "        #One hot encoding RGB images\n",
    "        # wm_encoded = X2i\n",
    "        # np_wm = np.asarray(wm_encoded)\n",
    "\n",
    "        yield tf.cast(X2i[0],tf.float32), tf.cast(X1i[0], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "msk_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_augment_generator(train_datagen, msk_datagen, \"Data/Dataset1000/Train/\", GENERATE_SQUARE, batch_size=BATCH_SIZE)\n",
    "valid_generator = train_augment_generator(train_datagen, msk_datagen, \"Data/Dataset1000/Train/\", GENERATE_SQUARE, batch_size=BATCH_SIZE)\n",
    "test_generator = train_augment_generator(train_datagen, msk_datagen, \"Data/Dataset1000/Train/\", GENERATE_SQUARE, batch_size=BATCH_SIZE)\n",
    "\n",
    "throw_away_gen = train_datagen.flow_from_directory(\n",
    "    directory=\"Data/Dataset1000/Train/WM_Images/\",\n",
    "    target_size=(GENERATE_SQUARE, GENERATE_SQUARE),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"input\",\n",
    "    shuffle=True,\n",
    "    seed=SEED)\n",
    "\n",
    "test_away_gen = train_datagen.flow_from_directory(\n",
    "    directory=\"Data/Dataset1000/Test/WM_Images/\",\n",
    "    target_size=(GENERATE_SQUARE, GENERATE_SQUARE),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"input\",\n",
    "    shuffle=True)\n",
    "\n",
    "unseen_test_away_gen = train_datagen.flow_from_directory(\n",
    "    directory=\"Data/Dataset1000/UnseenTest/\",\n",
    "    target_size=(GENERATE_SQUARE, GENERATE_SQUARE),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"input\",\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "batch_index = 0\n",
    "\n",
    "data = next(train_generator)\n",
    "\n",
    "plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=throw_away_gen.n//BATCH_SIZE\n",
    "STEP_SIZE_VALID=throw_away_gen.n//BATCH_SIZE\n",
    "\n",
    "print(STEP_SIZE_TRAIN,STEP_SIZE_VALID)\n",
    "print(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape, base_number_of_filters, leak = 0.2, channels = 3, kernel_size = (3,3), strides = (2,2) ):\n",
    "    \n",
    "    # f = config.base_number_of_filters\n",
    "    # k = config.kernel_size\n",
    "    # s = config.strides\n",
    "    # sz = config.train_size\n",
    "    # c = config.channels\n",
    "\n",
    "    model = Sequential([\n",
    "      layers.Input(shape=(image_shape, image_shape, channels)),\n",
    "      layers.Conv2D(base_number_of_filters, kernel_size, strides, padding=\"same\", name=\"dconv0\"),\n",
    "      layers.LeakyReLU(leak, name=\"dact0\"),\n",
    "\n",
    "      layers.Conv2D(2*base_number_of_filters, kernel_size, strides, padding=\"same\", name=\"dconv1\"),\n",
    "      layers.BatchNormalization(name=\"dbn1\"),\n",
    "      layers.LeakyReLU(leak, name=\"dact1\"),\n",
    "\n",
    "      layers.Conv2D(4*base_number_of_filters, kernel_size, strides, padding=\"same\", name=\"dconv2\"),\n",
    "      layers.BatchNormalization(name=\"dbn2\"),\n",
    "      layers.LeakyReLU(leak, name=\"dact2\"),\n",
    "\n",
    "      Conv2D(8*base_number_of_filters, kernel_size, strides, padding=\"same\", name=\"dconv3\"),\n",
    "      layers.BatchNormalization(name=\"dbn3\"),\n",
    "      layers.LeakyReLU(leak, name=\"dact3\"),\n",
    "\n",
    "      layers.Flatten(name=\"dflatout\"),\n",
    "      layers.Dense(1, name=\"ddenseout\")])\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "class Denoise(Model):\n",
    "  def __init__(self, in_shp):\n",
    "    super(Denoise, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape=(in_shp, in_shp, 3)),\n",
    "      layers.Conv2D(256, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(128, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(64, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(32, (3,3), activation='relu', padding='same', strides=2),      \n",
    "      ])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "\n",
    "      layers.Conv2DTranspose(32, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(128, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(256, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2D(3, kernel_size=(3,3), activation='sigmoid', padding='same')\n",
    "      ])\n",
    "    \n",
    "    \n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "class Denoise_Bigger(Model):\n",
    "  def __init__(self, in_shp):\n",
    "    super(Denoise_Bigger, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape=(in_shp, in_shp, 3)),\n",
    "      layers.Conv2D(256, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(128, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(64, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(32, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(16, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2)\n",
    "      ])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "\n",
    "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(32, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(128, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(256, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2D(3, kernel_size=(3,3), activation='sigmoid', padding='same')\n",
    "      ])\n",
    "    \n",
    "    \n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true))) \n",
    "\n",
    "def get_random_string(length):\n",
    "    letters = string.ascii_lowercase\n",
    "    result_str = ''.join(rnd.choice(letters) for i in range(length))\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(GENERATE_SQUARE)\n",
    "autoencoder = Denoise(GENERATE_SQUARE)\n",
    "autoencoder.compile(optimizer='adam', loss=root_mean_squared_error)\n",
    "weight_path = \"Weights/20200915-225635/_pretrained_weights0005.h5\"\n",
    "\n",
    "\n",
    "time_stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_dir = f'Weights\\\\{time_stamp}\\\\'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir + '_pretrained_weights{epoch:04d}.h5', save_weights_only=True, save_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################BIGGER VERSION#############################\n",
    "print(GENERATE_SQUARE)\n",
    "autoencoder = Denoise_Bigger(GENERATE_SQUARE)\n",
    "autoencoder.compile(optimizer='nadam', loss=root_mean_squared_error)\n",
    "weight_path = \"Weights_Bigger/20200928-002356/_pretrained_weights0034.h5\"\n",
    "\n",
    "\n",
    "time_stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_dir = f'Weights_Bigger\\\\{time_stamp}\\\\'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir + '_pretrained_weights{epoch:04d}.h5', save_weights_only=True, save_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.build((1,GENERATE_SQUARE,GENERATE_SQUARE,3))\n",
    "autoencoder.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20000,\n",
    "                    callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.build((1,GENERATE_SQUARE,GENERATE_SQUARE,3))\n",
    "# autoencoder.load_weights(weight_path)\n",
    "autoencoder.load_weights(weight_path)"
   ]
  },
  {
   "source": [
    "# **Copyrightous Disapearus**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "batch_index = 0\n",
    "\n",
    "data = test_away_gen.next()\n",
    "data_list.append(data[1][:-BATCH_SIZE+1])\n",
    "batch_index = batch_index + 1\n",
    "print(np.array(data_list[0]).shape)\n",
    "\n",
    "predicted = autoencoder.predict(data_list[0])\n",
    "predicted_twice = autoencoder.predict(predicted)\n",
    "predicted_thrice = autoencoder.predict(predicted_twice)\n",
    "\n",
    "# print(predicted)\n",
    "print(predicted.shape)\n",
    "plt.imshow(data[1][0])\n",
    "\n",
    "# cv2.imshow('image',predicted[0]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_twice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_thrice[0])"
   ]
  },
  {
   "source": [
    " <img src=\"Assets/Pipeline.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnd_string = get_random_string(10)\n",
    "print(rnd_string)\n",
    "cv2.imwrite(f\"Output/im_{rnd_string}_original.png\", cv2.cvtColor(data[1][0]*255., cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(f\"Output/im_{rnd_string}_1.png\", cv2.cvtColor( predicted[0]*255., cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(f\"Output/im_{rnd_string}_2.png\", cv2.cvtColor( predicted_twice[0]*255., cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(f\"Output/im_{rnd_string}_3.png\", cv2.cvtColor( predicted_thrice[0]*255., cv2.COLOR_RGB2BGR))"
   ]
  }
 ]
}